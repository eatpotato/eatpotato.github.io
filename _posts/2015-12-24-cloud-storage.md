---
layout: post
title: 对三种分布式存储的学习以及认识
date:       2015-12-24
author:     xue
catalog:    true
tags:
    - openstack
---
## 分布式存储

&emsp;&emsp;在一本云计算书中在看到Swift存储的时候，在网上搜到了陈沙克老师（真是大神级人物啊）的关于Ceph存储的一篇文章，原文链接：[统一存储：Ceph](http://www.chenshake.com/unified-storage-ceph/ "Title")。博客中提到，一般来说，企业如果规模大点，基本都需要用到3种存储： 
 
- 对象存储
- 文件存储
- 块存储  

&emsp;&emsp;这3种存储，有自己特有的应用场景，无法互相取代。 

&emsp;&emsp;关于对象存储，我接触过的有Swift;文件存储，我接触过HDFS；块存储，我接触过Cinder。为了搞清它们的应用场景和区别，我决定查一些资料并写篇博客记录下来。

## 对象存储 

&emsp;&emsp;在我本科快结束的时候，去信联云通(一家云计算公司)面试，当时CTO曾问我，Swift是什么？我答：对象存储。那对象存储适合什么样的应用场景呢？我却支支吾吾的答不上来（那个时候只是装过OpenStack，知道有哪些组件，至于这些组件之间的关系以及原理真是知之甚少）。他的回答我到现在还记得，对象存储适合于比较适合于存放静态数据，比如：图片、视频等。    
&emsp;&emsp;所以概括来说：**Swift比较适合于存放静态数据**，所谓的**静态数据指的是长期不会发生更新的数据**，或者在一定时期内更新频率比较低的数据。比如说虚拟机的镜像、多媒体数据以及数据的备份。如果需要实时地更新数据，那么Swift并不是一个特别好的选择，在这种情况下，**Cinder块存储更为合适。**  
&emsp;&emsp;对象存储也就是通常意义的键值存储，其接口就是简单的GET、PUT、DEL和其他扩展，开源项目或商业实现有：七牛、又拍、Swift、S3。
##文件存储

&emsp;&emsp;分布式文件存储概括起来：**通常意义是支持POSIX接口，具有统一的命名空间和目录树的结构**，典型设备：FTP、NFS服务器，**它解决了文件无法共享的问题**。  
&emsp;&emsp;文件存储也有软硬一体化的设备，但是其实普通拿一台服务器/笔记本，只要装上合适的操作系统与软件，接可以架设FTP与NFS服务了，架上该类服务之后的服务器，就是文件存储的一种了。主机A可以直接对文件存储进行文件的上传下载，与块存储不同，主机A不需要再对文件存储进行格式化了，因为文件管理功能已经由文件存储自己搞定了。 
 
优点：  
- 造价较低：随便一台机器就可以。  
- 方便文件共享。

缺点：  
- 读写速率低  
- 传输速度慢



## 块存储

&emsp;&emsp;块存储主要是将裸磁盘空间整个映射给主机使用的，例如磁盘阵列里面有五块磁盘（假设每个磁盘1G），那么可以通过划逻辑盘、做Raid、或者LVM（逻辑卷）等种种方式逻辑划分出N个逻辑的硬盘，假设划分完的逻辑盘也是五个，每个也是1G，但是这五个1G的逻辑盘已经与原来的五个物理硬盘意义完全不同了。例如第一个逻辑硬盘A里面，可能第一个200M是来自物理硬盘1，第二个200M是来自物理硬盘2，所以逻辑硬盘A是由多个物理硬盘逻辑虚构出来的。接着块存储会采用映射的方式将这几个逻辑盘映射给主机，主机上面的操作系统会识别有五块硬盘，但是操作系统是区别不出是逻辑的还是物理的，它一概认为只是五块裸的物理硬盘而已，跟直接拿一块物理硬盘挂在到操作系统没有区别，至少操作系统上没有区别。在这种方式下，操作系统还需要对挂载的裸硬盘进行分区、格式化后，才能使用，与平常主机内置硬盘的方式完全无异。

优点：  
- 数据得到了保护：因为通过了Raid与LVM等手段，对数据提供了保护。  
- 可以将廉价的硬盘组合起来，称为一个大容量的逻辑盘对外提供服务，提高了容量。
- 写入数据时，由于是多块磁盘组合出来的逻辑盘，所以几块磁盘可以并行写入，提升了读写效率。  
- 很多块存储采用SAN架构组网，传输速率以及封装协议的原因，使得传输速度与读写速率得到提升。

缺点：  
- 采用SAN架构组网时，需要额外为主机购买光纤通道卡，还要买光纤交换机，造价成本高  
- 主机之间的数据无法共享，在服务器不做集群的情况下，块存储裸盘映射给主机，再格式化后使用，对主机来说相当于本地盘，无法共享数据。
- 不利于不同操作系统主机间的数据共享。

## 对象存储与文件存储

&emsp;&emsp;对象存储和文件存储的区别是不大的，存储的都是一样的东西，只是抛弃了统一的命名空间和目录树的结构，使得扩展起来桎梏少一些。  
&emsp;&emsp;就像文件一样，对象包含数据，但是和文件不同的是，**对象在一个层结构中不会再有层级结构**。每个对象都在一个被称作存储池的扁平地址空间的同一级别里，一个对象不会属于另一个对象的下一级。此外，像FAT32这种文件系统，是直接**将一份文件的数据与metadata一起存储的**，存储过程先将文件按照文件系统的最小块大小来打散（如4M的文件，假设文件系统要求一个块4K，那就会分成1000块），再写进硬盘里面，过程中没有区分数据/metadata的。而**每个块最后会告知你下一个要存取的块的地址**，然后一直这样顺序地按图索骥，最后完成整个文件的所有块的读取。  
&emsp;&emsp;这种情况下读写速率很慢，就算你有100个机器手臂在读写，但是由于你只有读取到上一个块，才能知道下一块在哪里，其实相当于只有1个机器手臂在实际工作。而对象存储则将元数据独立了出来，控制节点交做数据服务器（服务器+对象存储管理软件），里面主要负责存储元数据信息，而其他负责存储对象数据的分布式服务器叫做OSD，主要负责存储文件的数据部分。当用户访问对象，会先访问元数据服务器，元数据服务器只负责反馈对象存储在哪些OSD，根据反馈信息用户再去访问OSD服务器去读取数据，这时就可以**并行读写**，所以访问速度就加快了。

## 对象存储与块存储
&emsp;&emsp;独立的互联网存储服务一般都是做对象存储的，因为**块存储是给计算机用的**，**对象存储是给浏览器等HTTP客户端用的**。独立服务所提供的存储系统，访问都来自互联网，自然是做对象存储；与之相对应，大部分类AWS的主机服务商都会提供一个块存储服务搭配主机服务。对象存储还可以支撑块存储的快照、主机的系统镜像存储等应用，可以相互结合的。  
&emsp;&emsp;访问延迟方面：

- 对于块存储，要求的访问时延是 10ms 级的，因为给虚拟机用的，传统硬盘也是10ms 级的时延，请求尺寸都很小，但qps（iops）可能会很高，那么在这种情况下：
	- 异地多中心是不现实的，存储要和主机尽量接近，相应地可靠性必然会有所打折
	- 强一致副本不会过多，强一致要求对时延有影响
- 对于对象存储，要求的访问时延是 100ms - 1s 级的，请求一般是中到大尺寸，低 qps 的，在这种情况下：
	- 可以用更多的分散副本数来换取更高的可靠性，但过多副本增加维持一致性的难度，需要折中。



参考文章：[座谈会有关分布式存储的三个问题](http://www.infoq.com/cn/articles/virtual-forum-three-basic-issues-about-distributed-storage "reference")
